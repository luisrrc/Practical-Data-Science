In the second course of the Practical Data Science Specialization, you will learn to automate a natural language processing task by building an end-to-end machine learning pipeline using Hugging Face’s highly-optimized implementation of the state-of-the-art BERT algorithm with Amazon SageMaker Pipelines. Your pipeline will first transform the dataset into BERT-readable features and store the features in the Amazon SageMaker Feature Store. It will then fine-tune a text classification model to the dataset using a Hugging Face pre-trained model, which has learned to understand the human language from millions of Wikipedia documents. Finally, your pipeline will evaluate the model’s accuracy and only deploy the model if the accuracy exceeds a given threshold.

**- Week 1: Feature Engineering and Feature Store:** Transform a raw text dataset into machine learning features and store features in a feature store.

**- Week 2: Train, Debug, and Profile a Machine Learning Model:** Fine-tune, debug, and profile a pre-trained BERT model.

**- Week 3: Deploy End-To-End Machine Learning pipelines:** Orchestrate ML workflows and track model lineage and artifacts in an end-to-end machine learning pipeline.


